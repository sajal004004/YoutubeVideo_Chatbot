{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j_S7x6jPqlj"
      },
      "outputs": [],
      "source": [
        "#1. Install necessary libraries\n",
        "!pip install -q \"openai>=1.0.0\" \"qdrant-client[fastembed]\" langchain langchain-openai yt-dlp langchain-community pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #2. Import libraries and set up the API key\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import yt_dlp\n",
        "import collections\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from pydub import AudioSegment\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Qdrant"
      ],
      "metadata": {
        "id": "6vSP-mjHjHtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely get the API key from Colab Secrets\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    client = OpenAI()\n",
        "    print(\"OpenAI client initialized.\")\n",
        "except (ImportError, KeyError):\n",
        "    print(\" OpenAI API key not found. Please add it to Colab Secrets.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJCj6xyVjXxD",
        "outputId": "3e4bb3d7-a504-4b97-b86f-1d56d44e4e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Segment structure once for clarity and reuse\n",
        "Segment = collections.namedtuple(\"Segment\", [\"start\", \"end\", \"text\"])\n",
        "\n",
        "def get_video_id(url: str) -> str | None:\n",
        "    \"\"\"Extracts the YouTube video ID from a URL.\"\"\"\n",
        "    match = re.search(r\"(?:v=|\\/|embed\\/|youtu\\.be\\/)([a-zA-Z0-9_-]{11})\", url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def format_time(seconds: float) -> str:\n",
        "    \"\"\"Formats seconds into MM:SS format.\"\"\"\n",
        "    minutes = int(seconds // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{minutes:02d}:{seconds:02d}\""
      ],
      "metadata": {
        "id": "SVRKkcowjZiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transcript_segments(video_url: str):\n",
        "    CACHE_DIR = \"transcript_cache_en\"\n",
        "    TXT_OUTPUT_DIR = \"text_transcripts_en\"\n",
        "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "    os.makedirs(TXT_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    video_id = get_video_id(video_url)\n",
        "    if not video_id:\n",
        "        raise ValueError(\"Could not extract video ID from URL.\")\n",
        "\n",
        "    cache_file_path = os.path.join(CACHE_DIR, f\"{video_id}.json\")\n",
        "\n",
        "    if os.path.exists(cache_file_path):\n",
        "        try:\n",
        "            print(f\" Loading translated transcript from cache for video ID: {video_id}\")\n",
        "            with open(cache_file_path, 'r', encoding='utf-8') as f:\n",
        "                cached_data = json.load(f)\n",
        "            if not cached_data:\n",
        "                 raise json.JSONDecodeError(\"Cache file is empty\", \"\", 0)\n",
        "            return [Segment(s['start'], s['end'], s['text']) for s in cached_data]\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\" Corrupted cache file found for {video_id}. Deleting and re-processing.\")\n",
        "            os.remove(cache_file_path)\n",
        "\n",
        "    print(f\" No cache found. Processing video for translation: {video_id}\")\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3'}],\n",
        "        'outtmpl': f'{video_id}_temp_audio'\n",
        "    }\n",
        "    audio_file_path = f\"{video_id}_temp_audio.mp3\"\n",
        "\n",
        "    start_download_time = time.perf_counter()\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([video_url])\n",
        "    end_download_time = time.perf_counter()\n",
        "    print(f\" Audio download time: {end_download_time - start_download_time:.2f} seconds\")\n",
        "\n",
        "    MAX_FILE_SIZE_MB = 24\n",
        "    file_size_mb = os.path.getsize(audio_file_path) / (1024 * 1024)\n",
        "    serializable_segments = []\n",
        "\n",
        "    if file_size_mb > MAX_FILE_SIZE_MB:\n",
        "        print(f\" Audio file is large ({file_size_mb:.2f} MB). Splitting into chunks...\")\n",
        "        audio = AudioSegment.from_mp3(audio_file_path)\n",
        "        num_chunks = math.ceil(file_size_mb / MAX_FILE_SIZE_MB)\n",
        "        chunk_length_ms = math.ceil(len(audio) / num_chunks)\n",
        "        time_offset_s = 0\n",
        "\n",
        "        for i in range(num_chunks):\n",
        "            start_ms = i * chunk_length_ms\n",
        "            end_ms = start_ms + chunk_length_ms\n",
        "            chunk = audio[start_ms:end_ms]\n",
        "            chunk_file_path = f\"{video_id}_chunk_{i}.mp3\"\n",
        "            chunk.export(chunk_file_path, format=\"mp3\")\n",
        "\n",
        "            print(f\"Translating chunk {i+1}/{num_chunks}...\")\n",
        "            start_chunk_time = time.perf_counter()\n",
        "            with open(chunk_file_path, \"rb\") as chunk_file_obj:\n",
        "                translation_response = client.audio.translations.create(\n",
        "                    model=\"whisper-1\",\n",
        "                    file=chunk_file_obj,\n",
        "                    response_format=\"verbose_json\"\n",
        "                )\n",
        "\n",
        "            response_segments = translation_response.segments\n",
        "            for segment in response_segments:\n",
        "                new_segment_dict = {\n",
        "                    'start': segment.start + time_offset_s,\n",
        "                    'end': segment.end + time_offset_s,\n",
        "                    'text': segment.text\n",
        "                }\n",
        "                serializable_segments.append(new_segment_dict)\n",
        "\n",
        "            end_chunk_time = time.perf_counter()\n",
        "            print(f\" Chunk {i+1} translation time: {end_chunk_time - start_chunk_time:.2f} seconds\")\n",
        "\n",
        "            if response_segments:\n",
        "                 time_offset_s = serializable_segments[-1]['end']\n",
        "            os.remove(chunk_file_path)\n",
        "    else:\n",
        "        print(\"Translating with OpenAI Whisper API...\")\n",
        "        start_translation_time = time.perf_counter()\n",
        "        with open(audio_file_path, \"rb\") as audio_file_obj:\n",
        "            translation_response = client.audio.translations.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file_obj,\n",
        "                response_format=\"verbose_json\"\n",
        "            )\n",
        "\n",
        "        serializable_segments = [\n",
        "            {'start': s.start, 'end': s.end, 'text': s.text}\n",
        "            for s in translation_response.segments\n",
        "        ]\n",
        "\n",
        "        end_translation_time = time.perf_counter()\n",
        "        print(f\" Translation time: {end_translation_time - start_translation_time:.2f} seconds\")\n",
        "\n",
        "    os.remove(audio_file_path)\n",
        "    print(\"Translation complete and audio file cleaned up.\")\n",
        "\n",
        "    with open(cache_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(serializable_segments, f, indent=2)\n",
        "    print(f\" Saved translated transcript to cache: {cache_file_path}\")\n",
        "\n",
        "    txt_file_path = os.path.join(TXT_OUTPUT_DIR, f\"{video_id}.txt\")\n",
        "    with open(txt_file_path, 'w', encoding='utf-8') as f:\n",
        "        for segment in serializable_segments:\n",
        "            timestamp = format_time(segment['start'])\n",
        "            f.write(f\"[{timestamp}] {segment['text'].strip()}\\n\")\n",
        "    print(f\" Saved human-readable translated transcript to: {txt_file_path}\")\n",
        "\n",
        "    return [Segment(s['start'], s['end'], s['text']) for s in serializable_segments]\n"
      ],
      "metadata": {
        "id": "o-LoxvdOjhlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_segments_into_documents(segments, max_duration_seconds=90):\n",
        "    documents = []\n",
        "    current_text = \"\"\n",
        "    if not segments: return []\n",
        "    current_start = segments[0].start\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        current_text += segment.text + \" \"\n",
        "        duration = segment.end - current_start\n",
        "        if duration >= max_duration_seconds or i == len(segments) - 1:\n",
        "            documents.append(Document(\n",
        "                page_content=current_text.strip(),\n",
        "                metadata={'start': current_start, 'end': segment.end}\n",
        "            ))\n",
        "            current_text = \"\"\n",
        "            if i < len(segments) - 1:\n",
        "                current_start = segments[i+1].start\n",
        "    return documents"
      ],
      "metadata": {
        "id": "WaZeWnEIjoGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_rag_pipeline(video_url: str):\n",
        "    raw_segments = get_transcript_segments(video_url)\n",
        "    documents = group_segments_into_documents(raw_segments)\n",
        "    print(f\"\\nGrouped transcript into {len(documents)} documents.\")\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Created {len(chunks)} chunks for the vector store.\")\n",
        "\n",
        "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    vector_store = Qdrant.from_documents(\n",
        "        chunks, embeddings_model, location=\":memory:\", collection_name=\"video_rag_session\"\n",
        "    )\n",
        "    print(\"âœ… Vector store is ready to be queried.\")\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "CYMNEft7jt4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_query(query: str, vector_store, video_url: str):\n",
        "    print(f\"\\nğŸ” Searching for content related to: '{query}'\")\n",
        "    start_retrieval_time = time.perf_counter()\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=5)\n",
        "    end_retrieval_time = time.perf_counter()\n",
        "    print(f\"â±ï¸ Retrieval time: {end_retrieval_time - start_retrieval_time:.4f} seconds\")\n",
        "\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "    sources = [doc.metadata for doc in retrieved_docs]\n",
        "\n",
        "    prompt = f\"Answer the user's query based ONLY on the following context. If the context doesn't contain the answer, say so.\\n\\nContext:\\n{context}\\n\\nQuery:\\n{query}\\n\\nAnswer:\"\n",
        "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    print(\"\\n Answer \")\n",
        "    print(answer)\n",
        "    print(\"\\n Sources from Video \")\n",
        "    video_base_url = video_url.split('&')[0]\n",
        "    for i, source_meta in enumerate(sources):\n",
        "        start_time = format_time(source_meta['start'])\n",
        "        timestamp_link = f\"{video_base_url}&t={int(source_meta['start'])}s\"\n",
        "        print(f\"Source {i+1} (starts at {start_time}): {timestamp_link}\")"
      ],
      "metadata": {
        "id": "kK5Ey_8nj0ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the YouTube video you want to query\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=l99lcuNhVrI\"\n",
        "# This will download, transcribe (if not cached), and create the vector store.\n",
        "print(f\"Starting setup for video: {YOUTUBE_URL}\")\n",
        "video_vector_store = setup_rag_pipeline(YOUTUBE_URL)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" Setup complete. You can now run the next cell to ask questions.\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "39Elg4sAP89z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_query(\n",
        "        \"what is the video about\",\n",
        "        video_vector_store,\n",
        "        YOUTUBE_URL\n",
        "    )"
      ],
      "metadata": {
        "id": "o_5C-rA6RKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z97J7m1_mBg0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}